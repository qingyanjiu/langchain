{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba5b73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install langchain-mcp-adapters\n",
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "OPENAI_API_KEY = 'sk-sdcxstsuwiefzutgkridojrlcovgaggxddyvaicqwynpxebq'\n",
    "llm = ChatOpenAI(model='Qwen/Qwen2.5-32B-Instruct',\n",
    "            api_key=OPENAI_API_KEY,\n",
    "            base_url='https://api.siliconflow.cn/v1',\n",
    "            streaming=True,\n",
    "            temperature=0,\n",
    "            request_timeout=120,\n",
    "            max_retries=0\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd79e4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tool() -> None:\n",
    "#     \"\"\"Testing tool.\"\"\"\n",
    "#     print(\"This is a test tool.\")\n",
    "    \n",
    "# tools = [tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac4df63",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MultiServerMCPClient(\n",
    "    {\n",
    "        \"math\": {\n",
    "            \"command\": \"python\",\n",
    "            # Replace with absolute path to your math_server.py file\n",
    "            \"args\": [\"/path/to/math_server.py\"],\n",
    "            \"transport\": \"stdio\",\n",
    "        },\n",
    "        \"weather\": {\n",
    "            # Ensure your start your weather server on port 8000\n",
    "            \"url\": \"http://localhost:8000/mcp\",\n",
    "            \"transport\": \"streamable_http\",\n",
    "        }\n",
    "    }\n",
    ")\n",
    "tools = await client.get_tools()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6115ee6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_react_agent(\n",
    "    llm,\n",
    "    tools=tools,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0c225c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import Image, display \n",
    "# display(Image(agent.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e281f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await agent.ainvoke({\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]})\n",
    "async for chunk in agent.astream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"北京天气如何\"}]},\n",
    "    # stream_mode=[\"updates\", \"messages\", \"custom\"]\n",
    "    stream_mode=[\"messages\", \"custom\"]\n",
    "):\n",
    "    try:\n",
    "        print(chunk[1][0].content, end='', flush=True)\n",
    "    except Exception as e:\n",
    "        print(chunk)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
